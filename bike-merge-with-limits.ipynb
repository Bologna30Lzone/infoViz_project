{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c8c1c42",
   "metadata": {},
   "source": [
    "# Merge Bike Counter Data with 2024 Speed Limits and Trim for ease-of-access\n",
    "\n",
    "In this notebook we will integrate data from the dataset obtained as the result of running [rdf-to-csv.ipynb](rdf-to-csv.ipynb) with another dataset about speed limits in Bologna (accessible [here](https://opendata.comune.bologna.it/explore/dataset/velocita-citta-30/)).\n",
    "\n",
    "To do so we will:\n",
    "\n",
    "1. Load and filter bike counter readings from January 16th 2024 onward\n",
    "2. Load the 2024 speed‐limit dataset, where streets are represented as LineString/MultiLineString\n",
    "3. Perform a spatial “nearest” join to associate each bike counter point with the speed limit of the closest street segment\n",
    "4. Export the merged result to a new CSV file\n",
    "5. Trim the dataset to daily measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c2ba3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd            # tabular data handling\n",
    "import geopandas as gpd        # spatial data handling\n",
    "from shapely.geometry import Point, shape  # point & geojson→geometry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2a0800",
   "metadata": {},
   "source": [
    "## File paths\n",
    "\n",
    "Modify these paths as needed to point to your downloaded files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ff5b903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the CSV of bike counters\n",
    "bike_csv = Path(\"colonnine-conta-bici.csv\")\n",
    "\n",
    "# Path to the speed limits CSV\n",
    "speed_csv = Path(\"velocita-citta-30.csv\")\n",
    "\n",
    "# Output path for the merged CSV\n",
    "merged_csv = Path(\"bike-merged.csv\")\n",
    "\n",
    "#Output path for the trimmed csv\n",
    "trimmed_csv = Path(\"bike-trimmed.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb2bae8",
   "metadata": {},
   "source": [
    "## Define loader functions\n",
    "\n",
    "Define two helper functions to read into GeoDataFrames:\n",
    "- `load_bike_counters` reads all readings (no date filter) and parses points.\n",
    "- `load_speed_limits` reads street lines (GeoJSON) and builds geometries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ddc43204",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_bike_counters(path: Path) -> gpd.GeoDataFrame:\n",
    "    df = pd.read_csv(path, parse_dates=['data'])\n",
    "    def to_point(s):\n",
    "        if pd.isna(s): return None\n",
    "        lat, lon = [x.strip() for x in s.split(',')]\n",
    "        return Point(float(lon), float(lat))\n",
    "    return gpd.GeoDataFrame(df,\n",
    "                            geometry=df['geo_point_2d'].apply(to_point),\n",
    "                            crs=\"EPSG:4326\")\n",
    "\n",
    "def load_speed_limits(path: Path) -> gpd.GeoDataFrame:\n",
    "    df = pd.read_csv(path, sep=';', encoding='utf-8-sig')\n",
    "    if 'Geo Shape' not in df:\n",
    "        raise ValueError(\"Missing 'Geo Shape' column\")\n",
    "    def parse_shape(js):\n",
    "        if pd.isna(js): return None\n",
    "        return shape(json.loads(js))\n",
    "    return gpd.GeoDataFrame(df,\n",
    "                            geometry=df['Geo Shape'].apply(parse_shape),\n",
    "                            crs=\"EPSG:4326\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3e34ce",
   "metadata": {},
   "source": [
    "## Mapping\n",
    "Extract one representative point per column, perform a single nearest-neighbor join against street lines (in a metric CRS), and build a mapping DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02d5b446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Load full bike data\n",
    "bike_full = load_bike_counters(bike_csv)\n",
    "\n",
    "# 2) Unique point per column\n",
    "unique_pts = (bike_full\n",
    "              .drop_duplicates(subset=\"colonnina\")\n",
    "              .loc[:, [\"colonnina\", \"geometry\"]]\n",
    "              .to_crs(epsg=32632))\n",
    "\n",
    "# 3) Load and reproject street lines\n",
    "speed_gdf = load_speed_limits(speed_csv).to_crs(epsg=32632)\n",
    "\n",
    "# 4) Spatial join once to get VEL2024 per colonnina\n",
    "mapping = (gpd.sjoin_nearest(unique_pts,\n",
    "                             speed_gdf[['VEL2024','geometry']],\n",
    "                             how='left',\n",
    "                             distance_col='dist_m')\n",
    "           .drop(columns=['geometry','dist_m','index_right'])\n",
    "           .set_index('colonnina')['VEL2024']\n",
    "           .rename('VEL2024')\n",
    "           .reset_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8500ebb2",
   "metadata": {},
   "source": [
    "## Merge function\n",
    "\n",
    "Merge the `VEL2024` mapping back onto all readings via pandas merge, drop geometry, and write out the final CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d7f97de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] 298436 rows written to bike-merged.csv\n"
     ]
    }
   ],
   "source": [
    "# Ensure full dataset in lat/lon (merge ignores geometry)\n",
    "bike_full = bike_full.to_crs(epsg=4326)\n",
    "\n",
    "# Merge\n",
    "merged = bike_full.merge(mapping, on=\"colonnina\", how=\"left\")\n",
    "\n",
    "# Export (dropping geometry)\n",
    "merged.drop(columns='geometry').to_csv(merged_csv, index=False)\n",
    "print(f\"[OK] {len(merged)} rows written to {merged_csv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ceef0d6",
   "metadata": {},
   "source": [
    "## Exemplar Visualization\n",
    "Load the merged CSV and display the first 10 rows with all columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0d8bdb50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>colonnina</th>\n",
       "      <th>totale</th>\n",
       "      <th>direzione_periferia</th>\n",
       "      <th>direzione_centro</th>\n",
       "      <th>geo_point_2d</th>\n",
       "      <th>data</th>\n",
       "      <th>VEL2024</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Orti_II</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.47624162079627,11.37609044129954</td>\n",
       "      <td>2025-06-09 21:00:00+00:00</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Murri_I</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.48440745989066,11.35658715560829</td>\n",
       "      <td>2025-06-09 20:00:00+00:00</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mazzini_II</td>\n",
       "      <td>130.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>130.0</td>\n",
       "      <td>44.48936290709702,11.35940582976347</td>\n",
       "      <td>2025-06-10 05:00:00+00:00</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sturzo_II</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.48820778081575,11.29599058158018</td>\n",
       "      <td>2025-06-10 07:00:00+00:00</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Massarenti_II</td>\n",
       "      <td>33.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.0</td>\n",
       "      <td>44.49300884795814,11.37056742338153</td>\n",
       "      <td>2025-06-10 02:00:00+00:00</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Zanardi_I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.50817288812807,11.32990298071598</td>\n",
       "      <td>2025-06-09 22:00:00+00:00</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Murri_II</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>44.48418981668801,11.35719458905058</td>\n",
       "      <td>2025-06-09 21:00:00+00:00</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Zanardi_II</td>\n",
       "      <td>191.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.5082267800901,11.32964907760978</td>\n",
       "      <td>2025-06-10 04:00:00+00:00</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Zanardi_II</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.5082267800901,11.32964907760978</td>\n",
       "      <td>2025-06-09 20:00:00+00:00</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Zanardi_II</td>\n",
       "      <td>68.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.5082267800901,11.32964907760978</td>\n",
       "      <td>2025-06-10 08:00:00+00:00</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       colonnina  totale  direzione_periferia  direzione_centro  \\\n",
       "0        Orti_II     3.0                  3.0               NaN   \n",
       "1        Murri_I     5.0                  5.0               NaN   \n",
       "2     Mazzini_II   130.0                  NaN             130.0   \n",
       "3      Sturzo_II    14.0                 14.0               NaN   \n",
       "4  Massarenti_II    33.0                  NaN              33.0   \n",
       "5      Zanardi_I     NaN                  NaN               NaN   \n",
       "6       Murri_II     7.0                  NaN               7.0   \n",
       "7     Zanardi_II   191.0                191.0               NaN   \n",
       "8     Zanardi_II     1.0                  1.0               NaN   \n",
       "9     Zanardi_II    68.0                 68.0               NaN   \n",
       "\n",
       "                          geo_point_2d                       data  VEL2024  \n",
       "0  44.47624162079627,11.37609044129954  2025-06-09 21:00:00+00:00       50  \n",
       "1  44.48440745989066,11.35658715560829  2025-06-09 20:00:00+00:00       50  \n",
       "2  44.48936290709702,11.35940582976347  2025-06-10 05:00:00+00:00       30  \n",
       "3  44.48820778081575,11.29599058158018  2025-06-10 07:00:00+00:00       50  \n",
       "4  44.49300884795814,11.37056742338153  2025-06-10 02:00:00+00:00       30  \n",
       "5  44.50817288812807,11.32990298071598  2025-06-09 22:00:00+00:00       30  \n",
       "6  44.48418981668801,11.35719458905058  2025-06-09 21:00:00+00:00       30  \n",
       "7   44.5082267800901,11.32964907760978  2025-06-10 04:00:00+00:00       30  \n",
       "8   44.5082267800901,11.32964907760978  2025-06-09 20:00:00+00:00       30  \n",
       "9   44.5082267800901,11.32964907760978  2025-06-10 08:00:00+00:00       30  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(merged_csv)\n",
    "pd.set_option('display.max_columns', None)\n",
    "display(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41cb7482",
   "metadata": {},
   "source": [
    "## Trim-to-daily function\n",
    "\n",
    "In order to ease future processing of data, we run this Python script that:\n",
    "\n",
    "1. **Reads** the raw hourly CSV (`bike-merged.csv`).  \n",
    "2. **Parses** the timestamp column into a simple date for grouping.  \n",
    "3. **Normalizes** counter names by stripping any `_I`/`_II` suffix so that split‐direction sensors merge into one.  \n",
    "4. **Fills** missing hourly counts with zero to avoid gaps.  \n",
    "5. **Groups** by (`colonnina`, `data`) and:\n",
    "   - **Sums** all hourly counts into a daily total.  \n",
    "   - **Carries over** the first observed `VEL2024` value for that counter.  \n",
    "6. **Writes** the resulting daily summary to `bike-trimmed.csv`.\n",
    "\n",
    "This will produce a clean dataset trimmed to daily measurements (instead of hourly).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1ed3b3b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bike-trimmed.csv created with 10718 records.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# read input file\n",
    "df = pd.read_csv(merged_csv)\n",
    "\n",
    "# parse date from timestamp\n",
    "df['data'] = pd.to_datetime(df['data']).dt.date\n",
    "\n",
    "# strip suffix _I or _II to unify counters\n",
    "df['colonnina'] = df['colonnina'].str.replace(r'(_I|_II)$', '', regex=True)\n",
    "\n",
    "# fill missing counts\n",
    "df['totale'] = df['totale'].fillna(0)\n",
    "\n",
    "# sum hourly counts per day and counter, keep first VEL2024\n",
    "daily = (\n",
    "    df.groupby(['colonnina', 'data'], as_index=False)\n",
    "      .agg(totale=('totale', 'sum'), VEL2024=('VEL2024', 'first'))\n",
    ")\n",
    "\n",
    "# write daily summary to CSV\n",
    "daily.to_csv(trimmed_csv, index=False)\n",
    "\n",
    "print(f\"bike-trimmed.csv created with {len(daily)} records.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bdca936",
   "metadata": {},
   "source": [
    "## Exemplar Visualization\n",
    "Load the trimmed CSV and display the first 10 rows with all columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "21db5211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>colonnina</th>\n",
       "      <th>data</th>\n",
       "      <th>totale</th>\n",
       "      <th>VEL2024</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ercolani</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>19.0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ercolani</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>464.0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ercolani</td>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>816.0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ercolani</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>987.0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ercolani</td>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>1037.0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ercolani</td>\n",
       "      <td>2019-01-05</td>\n",
       "      <td>704.0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ercolani</td>\n",
       "      <td>2019-01-06</td>\n",
       "      <td>713.0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ercolani</td>\n",
       "      <td>2019-01-07</td>\n",
       "      <td>1747.0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ercolani</td>\n",
       "      <td>2019-01-08</td>\n",
       "      <td>1884.0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ercolani</td>\n",
       "      <td>2019-01-09</td>\n",
       "      <td>1985.0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  colonnina        data  totale  VEL2024\n",
       "0  Ercolani  2018-12-31    19.0       50\n",
       "1  Ercolani  2019-01-01   464.0       50\n",
       "2  Ercolani  2019-01-02   816.0       50\n",
       "3  Ercolani  2019-01-03   987.0       50\n",
       "4  Ercolani  2019-01-04  1037.0       50\n",
       "5  Ercolani  2019-01-05   704.0       50\n",
       "6  Ercolani  2019-01-06   713.0       50\n",
       "7  Ercolani  2019-01-07  1747.0       50\n",
       "8  Ercolani  2019-01-08  1884.0       50\n",
       "9  Ercolani  2019-01-09  1985.0       50"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(trimmed_csv)\n",
    "pd.set_option('display.max_columns', None)\n",
    "display(df.head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
